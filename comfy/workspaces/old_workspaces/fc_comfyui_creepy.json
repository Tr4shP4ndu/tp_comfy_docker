{
    "3": {
        "inputs": {
            "seed": 2252,
            "steps": 35,
            "cfg": 8,
            "sampler_name": "dpmpp_sde_gpu",
            "scheduler": "karras",
            "denoise": 1,
            "model": [
                "4",
                0
            ],
            "positive": [
                "6",
                0
            ],
            "negative": [
                "7",
                0
            ],
            "latent_image": [
                "5",
                0
            ]
        },
        "class_type": "KSampler",
        "_meta": {
            "title": "KSampler"
        }
    },
    "4": {
        "inputs": {
            "ckpt_name": "leosamsHelloworldXL_helloworldXL32DPO.safetensors"
        },
        "class_type": "CheckpointLoaderSimple",
        "_meta": {
            "title": "Load Checkpoint"
        }
    },
    "5": {
        "inputs": {
            "width": 1024,
            "height": 1024,
            "batch_size": 1
        },
        "class_type": "EmptyLatentImage",
        "_meta": {
            "title": "Empty Latent Image"
        }
    },
    "6": {
        "inputs": {
            "text": "hyperdetailed photography, soft light, head portrait, (white background:1.3), skin details, sharp and in focus, \ngirl Korean idol, \nshort (pink:1.3) wavy hair, \nthich eyebrows, \nbig eyes, \nnarrow nose, \nsmile, \nslim",
            "clip": [
                "4",
                1
            ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
            "title": "CLIP Text Encode (Prompt)"
        }
    },
    "7": {
        "inputs": {
            "text": "(worst quality, low quality, normal quality, lowres, low details, oversatured, undersaturated, overexposed, underexposed, grayscale, bw, bad photyo, bad photography, bad art:1.4), \n(watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), \n(blur, blurry, grainy), \nmorbid, \nugly, \nasymetrical, \nmutated malformed, \nmutilated, \npoorly lit, \nbad shadow, draft, \ncropped, \nout of frame, \ncut off, \ncensored, \njpeg artifactrs, \nout of focuys, \nglitch, \nduplicate, \n(airbrush, cartoon, anime, semi-realistic, cgi, render, blender, digital, art, manga, amateur:1.3), \n(3D, 3D game, 3D game scene, 3D character:1.1), \nacne",
            "clip": [
                "4",
                1
            ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
            "title": "CLIP Text Encode (Prompt)"
        }
    },
    "8": {
        "inputs": {
            "samples": [
                "3",
                0
            ],
            "vae": [
                "4",
                2
            ]
        },
        "class_type": "VAEDecode",
        "_meta": {
            "title": "VAE Decode"
        }
    },
    "10": {
        "inputs": {
            "images": [
                "8",
                0
            ]
        },
        "class_type": "PreviewImage",
        "_meta": {
            "title": "Preview Image"
        }
    },
    "11": {
        "inputs": {
            "image": "ComfyUI_temp_ycpfs_00001_.png [temp]",
            "upload": "image"
        },
        "class_type": "LoadImage",
        "_meta": {
            "title": "Load Image"
        }
    },
    "13": {
        "inputs": {
            "width": 768,
            "height": 768,
            "position": "bottom-center",
            "x_offset": 0,
            "y_offset": -100,
            "image": [
                "11",
                0
            ]
        },
        "class_type": "ImageCrop+",
        "_meta": {
            "title": "ðŸ”§ Image Crop"
        }
    },
    "14": {
        "inputs": {
            "images": [
                "13",
                0
            ]
        },
        "class_type": "PreviewImage",
        "_meta": {
            "title": "Preview Image"
        }
    },
    "16": {
        "inputs": {
            "image": "clipspace/clipspace-mask-10228528.3.png [input]",
            "upload": "image"
        },
        "class_type": "LoadImage",
        "_meta": {
            "title": "Load Image"
        }
    },
    "17": {
        "inputs": {
            "weight": 0.5,
            "weight_faceidv2": 0.5,
            "weight_type": "linear",
            "combine_embeds": "concat",
            "start_at": 0,
            "end_at": 1,
            "embeds_scaling": "V only",
            "model": [
                "20",
                0
            ],
            "ipadapter": [
                "21",
                0
            ],
            "image": [
                "13",
                0
            ],
            "attn_mask": [
                "16",
                1
            ],
            "clip_vision": [
                "22",
                0
            ],
            "insightface": [
                "23",
                0
            ]
        },
        "class_type": "IPAdapterFaceID",
        "_meta": {
            "title": "IPAdapter FaceID"
        }
    },
    "18": {
        "inputs": {
            "ckpt_name": "Juggernaut_X_RunDiffusion_Hyper.safetensors"
        },
        "class_type": "CheckpointLoaderSimple",
        "_meta": {
            "title": "Load Checkpoint"
        }
    },
    "20": {
        "inputs": {
            "lora_name": "ip-adapter-faceid-plusv2_sd15_lora.safetensors",
            "strength_model": 0.4,
            "model": [
                "18",
                0
            ]
        },
        "class_type": "LoraLoaderModelOnly",
        "_meta": {
            "title": "LoraLoaderModelOnly"
        }
    },
    "21": {
        "inputs": {
            "ipadapter_file": "ip-adapter-faceid-plusv2_sdxl.bin"
        },
        "class_type": "IPAdapterModelLoader",
        "_meta": {
            "title": "IPAdapter Model Loader"
        }
    },
    "22": {
        "inputs": {
            "clip_name": "CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors"
        },
        "class_type": "CLIPVisionLoader",
        "_meta": {
            "title": "Load CLIP Vision"
        }
    },
    "23": {
        "inputs": {
            "provider": "CPU"
        },
        "class_type": "IPAdapterInsightFaceLoader",
        "_meta": {
            "title": "IPAdapter InsightFace Loader"
        }
    },
    "24": {
        "inputs": {
            "seed": 0,
            "steps": 35,
            "cfg": 8,
            "sampler_name": "dpmpp_sde_gpu",
            "scheduler": "karras",
            "denoise": 1,
            "model": [
                "17",
                0
            ],
            "positive": [
                "26",
                0
            ],
            "negative": [
                "27",
                0
            ],
            "latent_image": [
                "29",
                0
            ]
        },
        "class_type": "KSampler",
        "_meta": {
            "title": "KSampler"
        }
    },
    "25": {
        "inputs": {
            "samples": [
                "24",
                0
            ],
            "vae": [
                "18",
                2
            ]
        },
        "class_type": "VAEDecode",
        "_meta": {
            "title": "VAE Decode"
        }
    },
    "26": {
        "inputs": {
            "text": "Beautiful girl",
            "clip": [
                "18",
                1
            ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
            "title": "CLIP Text Encode (Prompt)"
        }
    },
    "27": {
        "inputs": {
            "text": "Clown",
            "clip": [
                "18",
                1
            ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
            "title": "CLIP Text Encode (Prompt)"
        }
    },
    "28": {
        "inputs": {
            "images": [
                "25",
                0
            ]
        },
        "class_type": "PreviewImage",
        "_meta": {
            "title": "Preview Image"
        }
    },
    "29": {
        "inputs": {
            "width": 1024,
            "height": 1024,
            "batch_size": 1
        },
        "class_type": "EmptyLatentImage",
        "_meta": {
            "title": "Empty Latent Image"
        }
    },
    "32": {
        "inputs": {
            "filename_prefix": "asd",
            "images": [
                "25",
                0
            ]
        },
        "class_type": "SaveImage",
        "_meta": {
            "title": "Save Image"
        }
    },
    "extra": {
        "workspace_info": {
            "id": "95dee500-c38f-48ba-a2b0-68076083b7bd"
        }
    }
}